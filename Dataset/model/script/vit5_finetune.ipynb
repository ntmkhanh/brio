{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5xC-yYkxXqr",
        "outputId": "752b2898-6e45-4ecb-94a7-2c71b95a0563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing collected packages: texttable, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, brotli, py7zr\n",
            "Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.2 pybcj-1.0.1 pycryptodomex-3.15.0 pyppmd-1.0.0 pyzstd-0.15.3 texttable-1.6.5\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.23.0 datasets==2.5.2 rouge-score nltk accelerate sentencepiece!=0.1.92 protobuf\n",
        "!pip install py7zr\n",
        "!pip install torch>=1.3 evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "68bbf77271f747829d7ebe5b7ab5bf0b",
            "b8424474433e49428558a62faac3c7be",
            "e63e3e0403dd4dd0a3386ff7fdb1b02c",
            "724619a548e14829b8814cadbcc82000",
            "78d6b30b4df94b74b5e1bd56157d7ef4",
            "ea7a5171242b44b9959b66e1be4ba723",
            "2e2afab54a674ee1b16ee5bbd9f99e8f",
            "5f4f30a855904f2d898063169947eabb",
            "9feb4d678b15442db4614807d2e4686d",
            "b2d6b6da352444a4a983746f1426cb8a",
            "e9346b513b6d4599a63436975f7f2e6b",
            "f2cc978378bf4cada749941cdb5ef7ff",
            "2fada7a7c5424569b5004716d5a0808c",
            "406d167d234540eabc9a77a631664688",
            "386a4e34d8374eea8072e1f99b3b4ddd",
            "a6431832942b4e0eb3fa43b56c40ce62",
            "fc7207fe8f2443c18493c0d219424a97"
          ]
        },
        "id": "4O3xz7rVxraH",
        "outputId": "07e63856-aca6-40be-fbd3-905998dcc794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHUS47aBx1Wd",
        "outputId": "c301c4e5-29ee-4113-e559-315d71915640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./vit5-finetune-v6/runs/Nov21_05-00-17_fb36cbecea73,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=./vit5-finetune-v6,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=2,\n",
            "per_device_train_batch_size=2,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=./vit5-finetune-v6,\n",
            "save_on_each_node=False,\n",
            "save_steps=5000,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "WARNING:datasets.builder:Using custom data configuration default-2ff6617c6e1e1ec6\n",
            "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-2ff6617c6e1e1ec6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\n",
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-2ff6617c6e1e1ec6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-2ff6617c6e1e1ec6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\n",
            "\r  0% 0/3 [00:00<?, ?it/s]\r100% 3/3 [00:00<00:00, 1003.34it/s]\n",
            "[INFO|configuration_utils.py:653] 2022-11-21 05:00:17,168 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--VietAI--vit5-base/snapshots/2209a38d735ede63e88f5aa52bcdc11a05a37b85/config.json\n",
            "[INFO|configuration_utils.py:705] 2022-11-21 05:00:17,171 >> Model config T5Config {\n",
            "  \"_name_or_path\": \"VietAI/vit5-base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.23.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 36096\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-11-21 05:00:17,200 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--VietAI--vit5-base/snapshots/2209a38d735ede63e88f5aa52bcdc11a05a37b85/spiece.model\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-11-21 05:00:17,201 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--VietAI--vit5-base/snapshots/2209a38d735ede63e88f5aa52bcdc11a05a37b85/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-11-21 05:00:17,201 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-11-21 05:00:17,201 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--VietAI--vit5-base/snapshots/2209a38d735ede63e88f5aa52bcdc11a05a37b85/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-11-21 05:00:17,201 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--VietAI--vit5-base/snapshots/2209a38d735ede63e88f5aa52bcdc11a05a37b85/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:2156] 2022-11-21 05:00:17,276 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--VietAI--vit5-base/snapshots/2209a38d735ede63e88f5aa52bcdc11a05a37b85/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2606] 2022-11-21 05:00:20,274 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:2615] 2022-11-21 05:00:20,274 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at VietAI/vit5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2ff6617c6e1e1ec6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9eceb6eaf7825815.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2ff6617c6e1e1ec6/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f50b81dd04fe23cb.arrow\n",
            "/content/./vit5-finetune-v6 is already a clone of https://huggingface.co/ynhi/vit5-finetune-v6. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/./vit5-finetune-v6 is already a clone of https://huggingface.co/ynhi/vit5-finetune-v6. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1607] 2022-11-21 05:00:26,149 >> ***** Running training *****\n",
            "[INFO|trainer.py:1608] 2022-11-21 05:00:26,149 >>   Num examples = 24000\n",
            "[INFO|trainer.py:1609] 2022-11-21 05:00:26,149 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:1610] 2022-11-21 05:00:26,149 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:1611] 2022-11-21 05:00:26,149 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "[INFO|trainer.py:1612] 2022-11-21 05:00:26,149 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1613] 2022-11-21 05:00:26,149 >>   Total optimization steps = 60000\n",
            "  0% 0/60000 [00:00<?, ?it/s][WARNING|logging.py:281] 2022-11-21 05:00:26,164 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 2.9522, 'learning_rate': 4.958333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 2.6737, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.08}\n",
            "{'loss': 2.5498, 'learning_rate': 4.875e-05, 'epoch': 0.12}\n",
            "{'loss': 2.5208, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.17}\n",
            "{'loss': 2.4371, 'learning_rate': 4.791666666666667e-05, 'epoch': 0.21}\n",
            "{'loss': 2.4452, 'learning_rate': 4.75e-05, 'epoch': 0.25}\n",
            "{'loss': 2.3777, 'learning_rate': 4.708333333333334e-05, 'epoch': 0.29}\n",
            "{'loss': 2.382, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.33}\n",
            "{'loss': 2.3362, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.38}\n",
            "{'loss': 2.3147, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.42}\n",
            "  8% 5000/60000 [21:58<3:56:57,  3.87it/s][INFO|trainer.py:2656] 2022-11-21 05:22:24,957 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-5000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 05:22:24,958 >> Configuration saved in ./vit5-finetune-v6/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 05:22:28,144 >> Model weights saved in ./vit5-finetune-v6/checkpoint-5000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 05:22:28,145 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 05:22:28,145 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-5000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 05:22:28,181 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-5000/spiece.model\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 05:22:38,821 >> tokenizer config file saved in ./vit5-finetune-v6/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 05:22:38,822 >> Special tokens file saved in ./vit5-finetune-v6/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 05:22:38,956 >> Copy vocab file to ./vit5-finetune-v6/spiece.model\n",
            "{'loss': 2.3037, 'learning_rate': 4.541666666666667e-05, 'epoch': 0.46}\n",
            "{'loss': 2.2799, 'learning_rate': 4.5e-05, 'epoch': 0.5}\n",
            "{'loss': 2.2533, 'learning_rate': 4.458333333333334e-05, 'epoch': 0.54}\n",
            "{'loss': 2.2598, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.58}\n",
            "{'loss': 2.2418, 'learning_rate': 4.375e-05, 'epoch': 0.62}\n",
            "{'loss': 2.2251, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.67}\n",
            "{'loss': 2.2301, 'learning_rate': 4.291666666666667e-05, 'epoch': 0.71}\n",
            "{'loss': 2.1989, 'learning_rate': 4.25e-05, 'epoch': 0.75}\n",
            "{'loss': 2.2214, 'learning_rate': 4.208333333333334e-05, 'epoch': 0.79}\n",
            "{'loss': 2.1994, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.83}\n",
            " 17% 10000/60000 [44:35<3:42:36,  3.74it/s][INFO|trainer.py:2656] 2022-11-21 05:45:01,723 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-10000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 05:45:01,725 >> Configuration saved in ./vit5-finetune-v6/checkpoint-10000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 05:45:05,235 >> Model weights saved in ./vit5-finetune-v6/checkpoint-10000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 05:45:05,237 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-10000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 05:45:05,237 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-10000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 05:45:05,297 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-10000/spiece.model\n",
            "{'loss': 2.1726, 'learning_rate': 4.125e-05, 'epoch': 0.88}\n",
            "{'loss': 2.172, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.92}\n",
            "{'loss': 2.1683, 'learning_rate': 4.041666666666667e-05, 'epoch': 0.96}\n",
            "{'loss': 2.1527, 'learning_rate': 4e-05, 'epoch': 1.0}\n",
            "{'loss': 2.0608, 'learning_rate': 3.958333333333333e-05, 'epoch': 1.04}\n",
            "{'loss': 2.1035, 'learning_rate': 3.9166666666666665e-05, 'epoch': 1.08}\n",
            "{'loss': 2.0723, 'learning_rate': 3.875e-05, 'epoch': 1.12}\n",
            "{'loss': 2.0438, 'learning_rate': 3.8333333333333334e-05, 'epoch': 1.17}\n",
            "{'loss': 2.0417, 'learning_rate': 3.791666666666667e-05, 'epoch': 1.21}\n",
            "{'loss': 2.0489, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25}\n",
            " 25% 15000/60000 [1:06:32<3:23:16,  3.69it/s][INFO|trainer.py:2656] 2022-11-21 06:06:59,077 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-15000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 06:06:59,078 >> Configuration saved in ./vit5-finetune-v6/checkpoint-15000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 06:07:02,206 >> Model weights saved in ./vit5-finetune-v6/checkpoint-15000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 06:07:02,206 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-15000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 06:07:02,207 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-15000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 06:07:02,245 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-15000/spiece.model\n",
            "{'loss': 2.038, 'learning_rate': 3.708333333333334e-05, 'epoch': 1.29}\n",
            "{'loss': 2.0436, 'learning_rate': 3.6666666666666666e-05, 'epoch': 1.33}\n",
            "{'loss': 2.0363, 'learning_rate': 3.625e-05, 'epoch': 1.38}\n",
            "{'loss': 2.0434, 'learning_rate': 3.5833333333333335e-05, 'epoch': 1.42}\n",
            "{'loss': 2.0107, 'learning_rate': 3.541666666666667e-05, 'epoch': 1.46}\n",
            "{'loss': 2.0135, 'learning_rate': 3.5e-05, 'epoch': 1.5}\n",
            "{'loss': 2.037, 'learning_rate': 3.458333333333333e-05, 'epoch': 1.54}\n",
            "{'loss': 2.031, 'learning_rate': 3.4166666666666666e-05, 'epoch': 1.58}\n",
            "{'loss': 2.0367, 'learning_rate': 3.375000000000001e-05, 'epoch': 1.62}\n",
            "{'loss': 2.006, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.67}\n",
            " 33% 20000/60000 [1:28:36<3:15:42,  3.41it/s][INFO|trainer.py:2656] 2022-11-21 06:29:03,041 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-20000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 06:29:03,042 >> Configuration saved in ./vit5-finetune-v6/checkpoint-20000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 06:29:06,138 >> Model weights saved in ./vit5-finetune-v6/checkpoint-20000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 06:29:06,139 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-20000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 06:29:06,140 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-20000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 06:29:06,182 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-20000/spiece.model\n",
            "{'loss': 2.0211, 'learning_rate': 3.291666666666667e-05, 'epoch': 1.71}\n",
            "{'loss': 2.0206, 'learning_rate': 3.2500000000000004e-05, 'epoch': 1.75}\n",
            "{'loss': 2.0272, 'learning_rate': 3.208333333333334e-05, 'epoch': 1.79}\n",
            "{'loss': 2.0177, 'learning_rate': 3.1666666666666666e-05, 'epoch': 1.83}\n",
            "{'loss': 1.9992, 'learning_rate': 3.125e-05, 'epoch': 1.88}\n",
            "{'loss': 2.0011, 'learning_rate': 3.0833333333333335e-05, 'epoch': 1.92}\n",
            "{'loss': 1.9951, 'learning_rate': 3.0416666666666666e-05, 'epoch': 1.96}\n",
            "{'loss': 1.9954, 'learning_rate': 3e-05, 'epoch': 2.0}\n",
            "{'loss': 1.899, 'learning_rate': 2.9583333333333335e-05, 'epoch': 2.04}\n",
            "{'loss': 1.9092, 'learning_rate': 2.916666666666667e-05, 'epoch': 2.08}\n",
            " 42% 25000/60000 [1:50:45<2:30:21,  3.88it/s][INFO|trainer.py:2656] 2022-11-21 06:51:11,996 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-25000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 06:51:11,997 >> Configuration saved in ./vit5-finetune-v6/checkpoint-25000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 06:51:15,163 >> Model weights saved in ./vit5-finetune-v6/checkpoint-25000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 06:51:15,164 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-25000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 06:51:15,165 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-25000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 06:51:15,207 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-25000/spiece.model\n",
            "{'loss': 1.9144, 'learning_rate': 2.8749999999999997e-05, 'epoch': 2.12}\n",
            "{'loss': 1.9259, 'learning_rate': 2.8333333333333335e-05, 'epoch': 2.17}\n",
            "{'loss': 1.9023, 'learning_rate': 2.791666666666667e-05, 'epoch': 2.21}\n",
            "{'loss': 1.9069, 'learning_rate': 2.7500000000000004e-05, 'epoch': 2.25}\n",
            "{'loss': 1.9161, 'learning_rate': 2.7083333333333332e-05, 'epoch': 2.29}\n",
            "{'loss': 1.8961, 'learning_rate': 2.6666666666666667e-05, 'epoch': 2.33}\n",
            "{'loss': 1.893, 'learning_rate': 2.625e-05, 'epoch': 2.38}\n",
            "{'loss': 1.8943, 'learning_rate': 2.5833333333333336e-05, 'epoch': 2.42}\n",
            "{'loss': 1.9197, 'learning_rate': 2.5416666666666667e-05, 'epoch': 2.46}\n",
            "{'loss': 1.9133, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
            " 50% 30000/60000 [2:12:46<2:16:25,  3.66it/s][INFO|trainer.py:2656] 2022-11-21 07:13:12,213 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-30000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 07:13:12,214 >> Configuration saved in ./vit5-finetune-v6/checkpoint-30000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 07:13:15,296 >> Model weights saved in ./vit5-finetune-v6/checkpoint-30000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 07:13:15,297 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-30000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 07:13:15,297 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-30000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 07:13:15,337 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-30000/spiece.model\n",
            "{'loss': 1.8868, 'learning_rate': 2.4583333333333332e-05, 'epoch': 2.54}\n",
            "{'loss': 1.8983, 'learning_rate': 2.4166666666666667e-05, 'epoch': 2.58}\n",
            "{'loss': 1.9095, 'learning_rate': 2.375e-05, 'epoch': 2.62}\n",
            "{'loss': 1.89, 'learning_rate': 2.3333333333333336e-05, 'epoch': 2.67}\n",
            "{'loss': 1.884, 'learning_rate': 2.2916666666666667e-05, 'epoch': 2.71}\n",
            "{'loss': 1.8856, 'learning_rate': 2.25e-05, 'epoch': 2.75}\n",
            "{'loss': 1.8647, 'learning_rate': 2.2083333333333333e-05, 'epoch': 2.79}\n",
            "{'loss': 1.8791, 'learning_rate': 2.1666666666666667e-05, 'epoch': 2.83}\n",
            "{'loss': 1.892, 'learning_rate': 2.125e-05, 'epoch': 2.88}\n",
            "{'loss': 1.8826, 'learning_rate': 2.0833333333333336e-05, 'epoch': 2.92}\n",
            " 58% 35000/60000 [2:34:50<1:30:55,  4.58it/s][INFO|trainer.py:2656] 2022-11-21 07:35:16,561 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-35000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 07:35:16,561 >> Configuration saved in ./vit5-finetune-v6/checkpoint-35000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 07:35:19,661 >> Model weights saved in ./vit5-finetune-v6/checkpoint-35000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 07:35:19,662 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-35000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 07:35:19,662 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-35000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 07:35:19,705 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-35000/spiece.model\n",
            "{'loss': 1.8493, 'learning_rate': 2.0416666666666667e-05, 'epoch': 2.96}\n",
            "{'loss': 1.8821, 'learning_rate': 2e-05, 'epoch': 3.0}\n",
            "{'loss': 1.7985, 'learning_rate': 1.9583333333333333e-05, 'epoch': 3.04}\n",
            "{'loss': 1.8042, 'learning_rate': 1.9166666666666667e-05, 'epoch': 3.08}\n",
            "{'loss': 1.797, 'learning_rate': 1.8750000000000002e-05, 'epoch': 3.12}\n",
            "{'loss': 1.7835, 'learning_rate': 1.8333333333333333e-05, 'epoch': 3.17}\n",
            "{'loss': 1.8029, 'learning_rate': 1.7916666666666667e-05, 'epoch': 3.21}\n",
            "{'loss': 1.8049, 'learning_rate': 1.75e-05, 'epoch': 3.25}\n",
            "{'loss': 1.7899, 'learning_rate': 1.7083333333333333e-05, 'epoch': 3.29}\n",
            "{'loss': 1.7996, 'learning_rate': 1.6666666666666667e-05, 'epoch': 3.33}\n",
            " 67% 40000/60000 [2:56:48<1:29:11,  3.74it/s][INFO|trainer.py:2656] 2022-11-21 07:57:14,173 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-40000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 07:57:14,174 >> Configuration saved in ./vit5-finetune-v6/checkpoint-40000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 07:57:17,340 >> Model weights saved in ./vit5-finetune-v6/checkpoint-40000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 07:57:17,341 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-40000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 07:57:17,341 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-40000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 07:57:17,387 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-40000/spiece.model\n",
            "{'loss': 1.8127, 'learning_rate': 1.6250000000000002e-05, 'epoch': 3.38}\n",
            "{'loss': 1.7952, 'learning_rate': 1.5833333333333333e-05, 'epoch': 3.42}\n",
            "{'loss': 1.8003, 'learning_rate': 1.5416666666666668e-05, 'epoch': 3.46}\n",
            "{'loss': 1.8144, 'learning_rate': 1.5e-05, 'epoch': 3.5}\n",
            "{'loss': 1.8043, 'learning_rate': 1.4583333333333335e-05, 'epoch': 3.54}\n",
            "{'loss': 1.8063, 'learning_rate': 1.4166666666666668e-05, 'epoch': 3.58}\n",
            "{'loss': 1.7971, 'learning_rate': 1.3750000000000002e-05, 'epoch': 3.62}\n",
            "{'loss': 1.7983, 'learning_rate': 1.3333333333333333e-05, 'epoch': 3.67}\n",
            "{'loss': 1.7909, 'learning_rate': 1.2916666666666668e-05, 'epoch': 3.71}\n",
            "{'loss': 1.7836, 'learning_rate': 1.25e-05, 'epoch': 3.75}\n",
            " 75% 45000/60000 [3:18:56<1:15:08,  3.33it/s][INFO|trainer.py:2656] 2022-11-21 08:19:22,489 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-45000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 08:19:22,490 >> Configuration saved in ./vit5-finetune-v6/checkpoint-45000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 08:19:25,583 >> Model weights saved in ./vit5-finetune-v6/checkpoint-45000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 08:19:25,584 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-45000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 08:19:25,584 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-45000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 08:19:25,624 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-45000/spiece.model\n",
            "{'loss': 1.7755, 'learning_rate': 1.2083333333333333e-05, 'epoch': 3.79}\n",
            "{'loss': 1.7996, 'learning_rate': 1.1666666666666668e-05, 'epoch': 3.83}\n",
            "{'loss': 1.7766, 'learning_rate': 1.125e-05, 'epoch': 3.88}\n",
            "{'loss': 1.7965, 'learning_rate': 1.0833333333333334e-05, 'epoch': 3.92}\n",
            "{'loss': 1.8101, 'learning_rate': 1.0416666666666668e-05, 'epoch': 3.96}\n",
            "{'loss': 1.7948, 'learning_rate': 1e-05, 'epoch': 4.0}\n",
            "{'loss': 1.728, 'learning_rate': 9.583333333333334e-06, 'epoch': 4.04}\n",
            "{'loss': 1.7235, 'learning_rate': 9.166666666666666e-06, 'epoch': 4.08}\n",
            "{'loss': 1.751, 'learning_rate': 8.75e-06, 'epoch': 4.12}\n",
            "{'loss': 1.7226, 'learning_rate': 8.333333333333334e-06, 'epoch': 4.17}\n",
            " 83% 50000/60000 [3:41:02<41:42,  4.00it/s][INFO|trainer.py:2656] 2022-11-21 08:41:29,089 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-50000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 08:41:29,090 >> Configuration saved in ./vit5-finetune-v6/checkpoint-50000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 08:41:32,204 >> Model weights saved in ./vit5-finetune-v6/checkpoint-50000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 08:41:32,205 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-50000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 08:41:32,205 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-50000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 08:41:32,253 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-50000/spiece.model\n",
            "{'loss': 1.7126, 'learning_rate': 7.916666666666667e-06, 'epoch': 4.21}\n",
            "{'loss': 1.7061, 'learning_rate': 7.5e-06, 'epoch': 4.25}\n",
            "{'loss': 1.7381, 'learning_rate': 7.083333333333334e-06, 'epoch': 4.29}\n",
            "{'loss': 1.7403, 'learning_rate': 6.666666666666667e-06, 'epoch': 4.33}\n",
            "{'loss': 1.7227, 'learning_rate': 6.25e-06, 'epoch': 4.38}\n",
            "{'loss': 1.7308, 'learning_rate': 5.833333333333334e-06, 'epoch': 4.42}\n",
            "{'loss': 1.7327, 'learning_rate': 5.416666666666667e-06, 'epoch': 4.46}\n",
            "{'loss': 1.733, 'learning_rate': 5e-06, 'epoch': 4.5}\n",
            "{'loss': 1.7163, 'learning_rate': 4.583333333333333e-06, 'epoch': 4.54}\n",
            "{'loss': 1.711, 'learning_rate': 4.166666666666667e-06, 'epoch': 4.58}\n",
            " 92% 55000/60000 [4:03:14<21:44,  3.83it/s][INFO|trainer.py:2656] 2022-11-21 09:03:40,929 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-55000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 09:03:40,930 >> Configuration saved in ./vit5-finetune-v6/checkpoint-55000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 09:03:44,110 >> Model weights saved in ./vit5-finetune-v6/checkpoint-55000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 09:03:44,111 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-55000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 09:03:44,111 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-55000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 09:03:44,158 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-55000/spiece.model\n",
            "{'loss': 1.7188, 'learning_rate': 3.75e-06, 'epoch': 4.62}\n",
            "{'loss': 1.724, 'learning_rate': 3.3333333333333333e-06, 'epoch': 4.67}\n",
            "{'loss': 1.7306, 'learning_rate': 2.916666666666667e-06, 'epoch': 4.71}\n",
            "{'loss': 1.7254, 'learning_rate': 2.5e-06, 'epoch': 4.75}\n",
            "{'loss': 1.7207, 'learning_rate': 2.0833333333333334e-06, 'epoch': 4.79}\n",
            "{'loss': 1.719, 'learning_rate': 1.6666666666666667e-06, 'epoch': 4.83}\n",
            "{'loss': 1.7097, 'learning_rate': 1.25e-06, 'epoch': 4.88}\n",
            "{'loss': 1.707, 'learning_rate': 8.333333333333333e-07, 'epoch': 4.92}\n",
            "{'loss': 1.7501, 'learning_rate': 4.1666666666666667e-07, 'epoch': 4.96}\n",
            "{'loss': 1.7078, 'learning_rate': 0.0, 'epoch': 5.0}\n",
            "100% 60000/60000 [4:25:27<00:00,  4.14it/s][INFO|trainer.py:2656] 2022-11-21 09:25:53,456 >> Saving model checkpoint to ./vit5-finetune-v6/checkpoint-60000\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 09:25:53,457 >> Configuration saved in ./vit5-finetune-v6/checkpoint-60000/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 09:25:56,539 >> Model weights saved in ./vit5-finetune-v6/checkpoint-60000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 09:25:56,540 >> tokenizer config file saved in ./vit5-finetune-v6/checkpoint-60000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 09:25:56,540 >> Special tokens file saved in ./vit5-finetune-v6/checkpoint-60000/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 09:25:56,586 >> Copy vocab file to ./vit5-finetune-v6/checkpoint-60000/spiece.model\n",
            "[INFO|trainer.py:1852] 2022-11-21 09:26:03,805 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 15937.6561, 'train_samples_per_second': 7.529, 'train_steps_per_second': 3.765, 'train_loss': 1.9568780985514322, 'epoch': 5.0}\n",
            "100% 60000/60000 [4:25:37<00:00,  3.76it/s]\n",
            "[INFO|trainer.py:2656] 2022-11-21 09:26:04,048 >> Saving model checkpoint to ./vit5-finetune-v6\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 09:26:04,049 >> Configuration saved in ./vit5-finetune-v6/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 09:26:07,331 >> Model weights saved in ./vit5-finetune-v6/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 09:26:07,332 >> tokenizer config file saved in ./vit5-finetune-v6/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 09:26:07,332 >> Special tokens file saved in ./vit5-finetune-v6/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 09:26:07,403 >> Copy vocab file to ./vit5-finetune-v6/spiece.model\n",
            "[INFO|trainer.py:2656] 2022-11-21 09:26:07,461 >> Saving model checkpoint to ./vit5-finetune-v6\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 09:26:07,466 >> Configuration saved in ./vit5-finetune-v6/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 09:26:11,089 >> Model weights saved in ./vit5-finetune-v6/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 09:26:11,090 >> tokenizer config file saved in ./vit5-finetune-v6/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 09:26:11,090 >> Special tokens file saved in ./vit5-finetune-v6/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 09:26:11,155 >> Copy vocab file to ./vit5-finetune-v6/spiece.model\n",
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n",
            "WARNING:huggingface_hub.repository:The progress bars may be unreliable.\n",
            "Upload file runs/Nov21_05-00-17_fb36cbecea73/events.out.tfevents.1669006826.fb36cbecea73.523.0:  15% 3.34k/22.8k [00:00<?, ?B/s]\n",
            "Upload file pytorch_model.bin:   0% 3.34k/862M [00:00<?, ?B/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 235k/862M [00:01<1:03:27, 237kB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 1.46M/862M [00:02<17:31, 858kB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:   0% 2.71M/862M [00:03<14:10, 1.06MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   0% 3.93M/862M [00:04<13:03, 1.15MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 5.16M/862M [00:05<12:30, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 6.36M/862M [00:06<12:17, 1.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 7.53M/862M [00:07<12:13, 1.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 8.73M/862M [00:08<12:07, 1.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 9.92M/862M [00:09<12:02, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 11.1M/862M [00:10<12:02, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   1% 12.3M/862M [00:11<11:59, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 13.6M/862M [00:12<11:41, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 14.8M/862M [00:13<11:39, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 16.0M/862M [00:14<11:33, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 17.2M/862M [00:15<11:39, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 18.4M/862M [00:16<11:39, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 19.6M/862M [00:17<11:40, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   2% 20.8M/862M [00:18<11:33, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 22.1M/862M [00:19<11:29, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 23.3M/862M [00:20<11:30, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 24.5M/862M [00:21<11:33, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 25.7M/862M [00:22<11:35, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 26.9M/862M [00:23<11:32, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 28.1M/862M [00:24<11:33, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   3% 29.3M/862M [00:25<11:32, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 30.5M/862M [00:26<11:31, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 31.7M/862M [00:27<11:28, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 32.9M/862M [00:28<11:23, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 34.1M/862M [00:29<11:26, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 35.3M/862M [00:30<11:27, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 36.5M/862M [00:31<11:31, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 37.6M/862M [00:32<11:54, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   4% 38.7M/862M [00:33<12:02, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 39.9M/862M [00:34<11:55, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 41.0M/862M [00:35<11:54, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 42.2M/862M [00:36<11:50, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 43.3M/862M [00:37<11:53, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 44.5M/862M [00:38<11:53, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 45.6M/862M [00:39<11:53, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   5% 46.7M/862M [00:40<11:51, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 47.9M/862M [00:41<11:56, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 49.0M/862M [00:42<12:05, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 50.1M/862M [00:43<11:54, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 51.3M/862M [00:44<11:52, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 52.4M/862M [00:45<11:51, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 53.5M/862M [00:46<11:51, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 54.7M/862M [00:47<11:56, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   6% 55.8M/862M [00:48<12:01, 1.17MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 56.9M/862M [00:49<12:02, 1.17MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 58.0M/862M [00:50<11:57, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 59.2M/862M [00:51<11:48, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 60.3M/862M [00:52<11:44, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 61.4M/862M [00:53<11:51, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 62.6M/862M [00:54<11:45, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   7% 63.7M/862M [00:55<11:51, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 64.8M/862M [00:56<11:54, 1.17MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 65.9M/862M [00:57<11:50, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 67.1M/862M [00:58<11:40, 1.19MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 68.3M/862M [00:59<11:27, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 69.4M/862M [01:00<11:24, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 70.6M/862M [01:01<11:23, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 71.8M/862M [01:02<11:20, 1.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   8% 73.0M/862M [01:03<11:15, 1.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 74.2M/862M [01:04<11:11, 1.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 75.4M/862M [01:05<11:06, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 76.6M/862M [01:06<11:00, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 77.7M/862M [01:07<11:05, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 78.9M/862M [01:08<11:06, 1.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 80.1M/862M [01:09<10:56, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:   9% 81.3M/862M [01:10<10:55, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 82.5M/862M [01:11<11:02, 1.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 83.6M/862M [01:12<10:59, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 84.8M/862M [01:13<10:58, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 86.1M/862M [01:14<10:50, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 87.3M/862M [01:15<10:46, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 88.5M/862M [01:16<10:44, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  10% 89.8M/862M [01:17<10:31, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 91.0M/862M [01:18<10:23, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 92.3M/862M [01:19<10:23, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 93.5M/862M [01:20<10:20, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 94.8M/862M [01:21<10:16, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 96.0M/862M [01:22<10:11, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 97.4M/862M [01:23<10:02, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  11% 98.6M/862M [01:24<09:59, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 99.9M/862M [01:25<09:58, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 101M/862M [01:26<09:59, 1.33MB/s] \u001b[A\n",
            "Upload file pytorch_model.bin:  12% 102M/862M [01:27<09:57, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 104M/862M [01:28<09:52, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 105M/862M [01:29<09:47, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 106M/862M [01:30<09:45, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  12% 108M/862M [01:31<09:45, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 109M/862M [01:32<09:44, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 110M/862M [01:33<09:41, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 112M/862M [01:34<09:37, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 113M/862M [01:35<09:35, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 114M/862M [01:36<09:44, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  13% 115M/862M [01:37<09:44, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 117M/862M [01:38<09:40, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 118M/862M [01:39<09:36, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 119M/862M [01:40<09:40, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 121M/862M [01:41<09:37, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 122M/862M [01:42<09:40, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 123M/862M [01:43<09:40, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  14% 124M/862M [01:44<09:35, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 126M/862M [01:45<09:33, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 127M/862M [01:46<09:34, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 128M/862M [01:47<09:32, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 130M/862M [01:48<09:29, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 131M/862M [01:49<09:29, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 132M/862M [01:50<09:32, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  15% 133M/862M [01:51<09:36, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 135M/862M [01:52<09:39, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 136M/862M [01:53<09:40, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 137M/862M [01:54<09:39, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 138M/862M [01:55<09:34, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 140M/862M [01:56<09:29, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 141M/862M [01:57<09:30, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  16% 142M/862M [01:58<09:27, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 143M/862M [01:59<09:26, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 145M/862M [02:00<09:22, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 146M/862M [02:01<09:16, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 147M/862M [02:02<09:17, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 149M/862M [02:03<09:16, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  17% 150M/862M [02:04<09:16, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 151M/862M [02:05<09:18, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 152M/862M [02:06<09:19, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 154M/862M [02:07<09:26, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 155M/862M [02:08<09:21, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 156M/862M [02:09<09:15, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 157M/862M [02:10<09:12, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  18% 159M/862M [02:11<09:10, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 160M/862M [02:12<09:08, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 161M/862M [02:13<09:07, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 163M/862M [02:14<09:06, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 164M/862M [02:15<09:05, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 165M/862M [02:16<09:07, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 167M/862M [02:17<08:55, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  19% 168M/862M [02:18<08:47, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 169M/862M [02:19<08:44, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 170M/862M [02:20<08:49, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 172M/862M [02:21<08:50, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 173M/862M [02:22<08:52, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 174M/862M [02:23<08:52, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  20% 176M/862M [02:24<08:57, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 177M/862M [02:25<08:58, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 178M/862M [02:26<08:54, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 179M/862M [02:27<08:50, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 181M/862M [02:28<08:45, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 182M/862M [02:29<08:46, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 183M/862M [02:30<08:46, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  21% 184M/862M [02:31<09:06, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 186M/862M [02:32<08:58, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 187M/862M [02:33<08:47, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 188M/862M [02:34<08:38, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 190M/862M [02:35<08:39, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 191M/862M [02:36<08:41, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 192M/862M [02:37<08:42, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  22% 194M/862M [02:38<08:47, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 195M/862M [02:39<08:52, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 196M/862M [02:40<08:51, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 197M/862M [02:41<08:44, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 199M/862M [02:42<08:41, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 200M/862M [02:43<08:38, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 201M/862M [02:44<08:39, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  23% 202M/862M [02:45<08:37, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 204M/862M [02:46<08:32, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 205M/862M [02:47<08:29, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 206M/862M [02:48<08:23, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 208M/862M [02:49<08:16, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 209M/862M [02:50<08:11, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  24% 210M/862M [02:51<08:11, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 212M/862M [02:52<08:13, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 213M/862M [02:53<08:18, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 214M/862M [02:54<08:22, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 216M/862M [02:55<08:19, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 217M/862M [02:56<08:21, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 218M/862M [02:57<08:21, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  25% 219M/862M [02:58<08:24, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 221M/862M [02:59<08:22, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 222M/862M [03:00<08:19, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 223M/862M [03:01<08:17, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 225M/862M [03:02<08:15, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 226M/862M [03:03<08:14, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  26% 227M/862M [03:04<08:09, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 228M/862M [03:05<08:07, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 230M/862M [03:06<08:08, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 231M/862M [03:07<08:09, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 232M/862M [03:08<08:12, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 234M/862M [03:09<08:11, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 235M/862M [03:10<08:12, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  27% 236M/862M [03:11<08:09, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 237M/862M [03:12<08:08, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 239M/862M [03:13<08:12, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 240M/862M [03:14<08:11, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 241M/862M [03:15<08:08, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 242M/862M [03:16<08:09, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 244M/862M [03:17<08:14, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  28% 245M/862M [03:18<08:12, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 246M/862M [03:19<08:07, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 248M/862M [03:20<07:59, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 249M/862M [03:21<07:46, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 250M/862M [03:22<07:42, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 252M/862M [03:23<07:44, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 253M/862M [03:24<07:47, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  29% 254M/862M [03:25<07:47, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 255M/862M [03:26<07:47, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 257M/862M [03:27<07:46, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 258M/862M [03:28<07:46, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 259M/862M [03:29<07:48, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 261M/862M [03:30<07:50, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  30% 262M/862M [03:31<07:49, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 263M/862M [03:32<07:45, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 264M/862M [03:33<07:44, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 266M/862M [03:34<07:45, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 267M/862M [03:35<07:47, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 268M/862M [03:36<07:48, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 269M/862M [03:37<07:54, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  31% 271M/862M [03:38<07:58, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 272M/862M [03:39<08:01, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 273M/862M [03:40<08:03, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 274M/862M [03:41<08:03, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 276M/862M [03:42<07:59, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 277M/862M [03:43<08:00, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 278M/862M [03:44<07:53, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  32% 279M/862M [03:45<07:48, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 281M/862M [03:46<07:41, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 282M/862M [03:47<07:38, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 283M/862M [03:48<07:38, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 284M/862M [03:49<07:38, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 286M/862M [03:50<07:37, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 287M/862M [03:51<07:30, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  33% 288M/862M [03:52<07:23, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 290M/862M [03:53<07:19, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 291M/862M [03:54<07:19, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 292M/862M [03:55<07:21, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 293M/862M [03:56<07:20, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 295M/862M [03:57<07:18, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 296M/862M [03:58<07:17, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  34% 297M/862M [03:59<07:15, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 299M/862M [04:00<07:15, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 300M/862M [04:01<07:17, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 301M/862M [04:02<07:18, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 302M/862M [04:03<07:18, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 304M/862M [04:04<07:17, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  35% 305M/862M [04:05<07:15, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 306M/862M [04:06<07:10, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 308M/862M [04:07<07:09, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 309M/862M [04:08<07:07, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 310M/862M [04:09<07:08, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 311M/862M [04:10<07:08, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 313M/862M [04:11<07:11, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  36% 314M/862M [04:12<07:15, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 315M/862M [04:13<07:16, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 316M/862M [04:14<07:19, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 318M/862M [04:15<07:20, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 319M/862M [04:16<07:23, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 320M/862M [04:17<07:25, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 321M/862M [04:18<07:27, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  37% 322M/862M [04:19<07:25, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 324M/862M [04:20<07:19, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 325M/862M [04:21<07:14, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 326M/862M [04:22<07:08, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 328M/862M [04:23<07:04, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 329M/862M [04:24<07:10, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 330M/862M [04:25<07:20, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  38% 331M/862M [04:26<07:25, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 332M/862M [04:27<07:26, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 333M/862M [04:28<07:19, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 335M/862M [04:29<07:06, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 336M/862M [04:30<07:01, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 337M/862M [04:31<06:56, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 339M/862M [04:32<06:50, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  39% 340M/862M [04:33<06:49, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 341M/862M [04:34<06:47, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 343M/862M [04:35<06:43, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 344M/862M [04:36<06:40, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 345M/862M [04:37<06:38, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 346M/862M [04:38<06:39, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 348M/862M [04:39<06:39, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  40% 349M/862M [04:40<06:39, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 350M/862M [04:41<06:40, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 351M/862M [04:42<06:43, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 353M/862M [04:43<06:45, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 354M/862M [04:44<06:47, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 355M/862M [04:45<06:45, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  41% 357M/862M [04:46<06:41, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 358M/862M [04:47<06:40, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 359M/862M [04:48<06:42, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 360M/862M [04:49<06:39, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 362M/862M [04:50<06:31, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 363M/862M [04:51<06:28, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 364M/862M [04:52<06:27, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  42% 365M/862M [04:53<06:26, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 367M/862M [04:54<06:30, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 368M/862M [04:55<06:34, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 369M/862M [04:56<06:34, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 370M/862M [04:57<06:32, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 372M/862M [04:58<06:29, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 373M/862M [04:59<06:26, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  43% 374M/862M [05:00<06:23, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 376M/862M [05:01<06:23, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 377M/862M [05:02<06:22, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 378M/862M [05:03<06:21, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 379M/862M [05:04<06:20, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 381M/862M [05:05<06:18, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 382M/862M [05:06<06:12, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  44% 383M/862M [05:07<06:10, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 385M/862M [05:08<06:11, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 386M/862M [05:09<06:11, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 387M/862M [05:10<06:10, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 388M/862M [05:11<06:09, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 390M/862M [05:12<06:09, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  45% 391M/862M [05:13<06:05, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 392M/862M [05:14<06:04, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 394M/862M [05:15<06:03, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 395M/862M [05:16<06:05, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 396M/862M [05:17<06:08, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 397M/862M [05:18<06:08, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 399M/862M [05:19<06:06, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  46% 400M/862M [05:20<06:02, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 401M/862M [05:21<05:59, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 402M/862M [05:22<05:56, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 404M/862M [05:23<05:55, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 405M/862M [05:24<05:55, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 406M/862M [05:25<05:52, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 408M/862M [05:26<05:47, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  47% 409M/862M [05:27<05:49, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 410M/862M [05:28<05:48, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 412M/862M [05:29<05:46, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 413M/862M [05:30<05:44, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 414M/862M [05:31<05:42, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 416M/862M [05:32<05:43, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  48% 417M/862M [05:33<05:43, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 418M/862M [05:34<05:40, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 419M/862M [05:35<05:38, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 421M/862M [05:36<05:36, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 422M/862M [05:37<05:37, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 423M/862M [05:38<05:39, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 425M/862M [05:39<05:39, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  49% 426M/862M [05:40<05:41, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 427M/862M [05:41<05:40, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 428M/862M [05:42<05:40, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 430M/862M [05:43<05:40, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 431M/862M [05:44<05:39, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 432M/862M [05:45<05:38, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 434M/862M [05:46<05:35, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  50% 435M/862M [05:47<05:34, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 436M/862M [05:48<05:31, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 437M/862M [05:49<05:32, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 439M/862M [05:50<05:28, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 440M/862M [05:51<05:29, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 441M/862M [05:52<05:27, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 443M/862M [05:53<05:26, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  51% 444M/862M [05:54<05:27, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 445M/862M [05:55<05:27, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 446M/862M [05:56<05:28, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 448M/862M [05:57<05:27, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 449M/862M [05:58<05:27, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 450M/862M [05:59<05:25, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  52% 451M/862M [06:00<05:23, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 453M/862M [06:01<05:18, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 454M/862M [06:02<05:19, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 455M/862M [06:03<05:15, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 457M/862M [06:04<05:09, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 458M/862M [06:05<05:07, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 459M/862M [06:06<05:04, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  53% 461M/862M [06:07<05:06, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 462M/862M [06:08<05:07, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 463M/862M [06:09<05:08, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 464M/862M [06:10<05:08, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 466M/862M [06:11<05:07, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 467M/862M [06:12<05:06, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 468M/862M [06:13<05:05, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  54% 470M/862M [06:14<05:03, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 471M/862M [06:15<05:00, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 472M/862M [06:16<04:59, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 474M/862M [06:17<04:56, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 475M/862M [06:18<04:54, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 476M/862M [06:19<04:54, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  55% 478M/862M [06:20<04:49, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 479M/862M [06:21<04:50, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 480M/862M [06:22<04:51, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 482M/862M [06:23<04:50, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 483M/862M [06:24<04:50, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 484M/862M [06:25<04:49, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 485M/862M [06:26<04:47, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  56% 487M/862M [06:27<04:47, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 488M/862M [06:28<04:46, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 489M/862M [06:29<04:43, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 491M/862M [06:30<04:43, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 492M/862M [06:31<04:43, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 493M/862M [06:32<04:43, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  57% 495M/862M [06:33<04:41, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 496M/862M [06:34<04:38, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 497M/862M [06:35<04:35, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 499M/862M [06:36<04:35, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 500M/862M [06:37<04:37, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 501M/862M [06:38<04:36, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 502M/862M [06:39<04:36, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  58% 504M/862M [06:40<04:35, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 505M/862M [06:41<04:34, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 506M/862M [06:42<04:32, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 508M/862M [06:43<04:31, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 509M/862M [06:44<04:31, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 510M/862M [06:45<04:29, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  59% 512M/862M [06:46<04:27, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 513M/862M [06:47<04:25, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 514M/862M [06:48<04:23, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 516M/862M [06:49<04:20, 1.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 517M/862M [06:50<04:18, 1.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 518M/862M [06:51<04:16, 1.41MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 520M/862M [06:52<04:13, 1.41MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  60% 521M/862M [06:53<04:15, 1.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 522M/862M [06:54<04:18, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 524M/862M [06:55<04:21, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 525M/862M [06:56<04:22, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 526M/862M [06:57<04:21, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 527M/862M [06:58<04:20, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 528M/862M [06:59<04:32, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  61% 530M/862M [07:00<04:39, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 531M/862M [07:01<04:39, 1.24MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 532M/862M [07:02<04:35, 1.26MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 533M/862M [07:03<04:26, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 535M/862M [07:04<04:21, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 536M/862M [07:05<04:18, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 537M/862M [07:06<04:15, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  62% 538M/862M [07:07<04:16, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 540M/862M [07:08<04:13, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 541M/862M [07:09<04:10, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 542M/862M [07:10<04:07, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 544M/862M [07:11<04:03, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 545M/862M [07:12<04:04, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  63% 546M/862M [07:13<04:05, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 547M/862M [07:14<04:11, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 549M/862M [07:15<04:12, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 550M/862M [07:16<04:10, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 551M/862M [07:17<04:07, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 552M/862M [07:18<04:04, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 554M/862M [07:19<04:02, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  64% 555M/862M [07:20<04:00, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 556M/862M [07:21<03:58, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 558M/862M [07:22<03:55, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 559M/862M [07:23<03:59, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 560M/862M [07:24<03:57, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 561M/862M [07:25<03:57, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 563M/862M [07:26<03:58, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  65% 564M/862M [07:27<04:00, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 565M/862M [07:28<04:25, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 566M/862M [07:29<04:33, 1.14MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 567M/862M [07:30<04:39, 1.11MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 568M/862M [07:31<04:28, 1.15MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 569M/862M [07:32<04:20, 1.18MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 570M/862M [07:33<04:14, 1.20MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 571M/862M [07:34<04:09, 1.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  66% 573M/862M [07:35<04:02, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 574M/862M [07:36<03:56, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 575M/862M [07:37<03:53, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 577M/862M [07:38<03:50, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 578M/862M [07:39<03:48, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 579M/862M [07:40<03:45, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 580M/862M [07:41<03:44, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  67% 582M/862M [07:42<03:44, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 583M/862M [07:43<03:45, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 584M/862M [07:44<03:43, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 585M/862M [07:45<03:43, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 587M/862M [07:46<03:41, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 588M/862M [07:47<03:40, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 589M/862M [07:48<03:36, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  68% 590M/862M [07:49<03:35, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 592M/862M [07:50<03:33, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 593M/862M [07:51<03:34, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 594M/862M [07:52<03:35, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 595M/862M [07:53<03:36, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 597M/862M [07:54<03:35, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 598M/862M [07:55<03:35, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  69% 599M/862M [07:56<03:34, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 600M/862M [07:57<03:30, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 602M/862M [07:58<03:28, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 603M/862M [07:59<03:27, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 604M/862M [08:00<03:27, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 605M/862M [08:01<03:23, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  70% 607M/862M [08:02<03:25, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 608M/862M [08:03<03:25, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 609M/862M [08:04<03:21, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 610M/862M [08:05<03:18, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 612M/862M [08:06<03:16, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 613M/862M [08:07<03:16, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 614M/862M [08:08<03:12, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  71% 616M/862M [08:09<03:11, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 617M/862M [08:10<03:09, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 618M/862M [08:11<03:08, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 619M/862M [08:12<03:07, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 621M/862M [08:13<03:05, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 622M/862M [08:15<03:05, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 623M/862M [08:16<03:04, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  72% 625M/862M [08:17<03:04, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 626M/862M [08:18<03:02, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 627M/862M [08:19<03:01, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 628M/862M [08:20<03:00, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 630M/862M [08:21<02:59, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 631M/862M [08:22<02:59, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  73% 632M/862M [08:23<02:58, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 634M/862M [08:24<02:58, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 635M/862M [08:25<02:57, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 636M/862M [08:26<02:57, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 637M/862M [08:27<02:55, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 639M/862M [08:28<02:53, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 640M/862M [08:29<02:51, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  74% 641M/862M [08:30<02:51, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 643M/862M [08:31<02:50, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 644M/862M [08:32<02:48, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 645M/862M [08:33<02:46, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 647M/862M [08:34<02:45, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 648M/862M [08:35<02:44, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 649M/862M [08:36<02:42, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  75% 650M/862M [08:37<02:42, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 652M/862M [08:38<02:40, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 653M/862M [08:39<02:40, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 654M/862M [08:40<02:39, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 656M/862M [08:41<02:40, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 657M/862M [08:42<02:39, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  76% 658M/862M [08:43<02:39, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 659M/862M [08:44<02:38, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 661M/862M [08:45<02:40, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 662M/862M [08:46<02:40, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 663M/862M [08:47<02:39, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 664M/862M [08:48<02:40, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 666M/862M [08:49<02:39, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 667M/862M [08:50<02:38, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  77% 668M/862M [08:51<02:38, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 669M/862M [08:52<02:37, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 670M/862M [08:53<02:37, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 672M/862M [08:54<02:35, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 673M/862M [08:55<02:33, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 674M/862M [08:56<02:30, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  78% 676M/862M [08:57<02:27, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 677M/862M [08:58<02:26, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 678M/862M [08:59<02:25, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 679M/862M [09:00<02:24, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 681M/862M [09:01<02:22, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 682M/862M [09:02<02:20, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 683M/862M [09:03<02:17, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  79% 685M/862M [09:04<02:15, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 686M/862M [09:05<02:14, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 687M/862M [09:06<02:12, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 689M/862M [09:07<02:11, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 690M/862M [09:08<02:10, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 691M/862M [09:09<02:09, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  80% 693M/862M [09:10<02:08, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 694M/862M [09:11<02:05, 1.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 695M/862M [09:12<02:05, 1.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 697M/862M [09:13<02:04, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 698M/862M [09:14<02:03, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 699M/862M [09:15<02:02, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 701M/862M [09:16<02:02, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  81% 702M/862M [09:17<01:59, 1.40MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 703M/862M [09:18<01:59, 1.39MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 704M/862M [09:19<02:01, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 706M/862M [09:20<01:59, 1.37MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 707M/862M [09:21<01:57, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 708M/862M [09:22<01:56, 1.38MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 710M/862M [09:23<01:57, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  82% 711M/862M [09:24<02:00, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 712M/862M [09:25<02:00, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 713M/862M [09:26<02:01, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 714M/862M [09:27<02:01, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 716M/862M [09:28<02:02, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 717M/862M [09:29<02:05, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 718M/862M [09:30<02:03, 1.22MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  83% 719M/862M [09:31<02:01, 1.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 720M/862M [09:32<02:00, 1.23MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 721M/862M [09:33<02:01, 1.21MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 723M/862M [09:34<01:56, 1.25MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 724M/862M [09:35<01:53, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 725M/862M [09:36<01:52, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 726M/862M [09:37<01:50, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  84% 728M/862M [09:38<01:50, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 729M/862M [09:39<01:50, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 730M/862M [09:40<01:48, 1.27MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 731M/862M [09:41<01:45, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 733M/862M [09:42<01:43, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 734M/862M [09:43<01:41, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 735M/862M [09:44<01:41, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  85% 736M/862M [09:45<01:40, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 738M/862M [09:46<01:38, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 739M/862M [09:47<01:37, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 740M/862M [09:48<01:37, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 741M/862M [09:49<01:36, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 743M/862M [09:50<01:35, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 744M/862M [09:51<01:33, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  86% 745M/862M [09:52<01:32, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 746M/862M [09:53<01:31, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 748M/862M [09:54<01:31, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 749M/862M [09:55<01:30, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 750M/862M [09:56<01:28, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 752M/862M [09:57<01:27, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 753M/862M [09:58<01:25, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  87% 754M/862M [09:59<01:26, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 755M/862M [10:00<01:24, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 757M/862M [10:01<01:23, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 758M/862M [10:02<01:22, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 759M/862M [10:03<01:22, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 760M/862M [10:04<01:21, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  88% 762M/862M [10:05<01:19, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 763M/862M [10:06<01:17, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 764M/862M [10:07<01:18, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 765M/862M [10:08<01:17, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 767M/862M [10:09<01:16, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 768M/862M [10:10<01:14, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 769M/862M [10:11<01:13, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  89% 770M/862M [10:12<01:12, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 772M/862M [10:13<01:11, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 773M/862M [10:14<01:10, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 774M/862M [10:15<01:09, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 776M/862M [10:16<01:08, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 777M/862M [10:17<01:06, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 778M/862M [10:18<01:05, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  90% 779M/862M [10:19<01:04, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 781M/862M [10:20<01:04, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 782M/862M [10:21<01:02, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 783M/862M [10:22<01:01, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 785M/862M [10:23<01:00, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 786M/862M [10:24<00:59, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 787M/862M [10:25<00:58, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  91% 788M/862M [10:26<00:58, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 790M/862M [10:27<00:56, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 791M/862M [10:28<00:55, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 792M/862M [10:29<00:54, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 793M/862M [10:30<00:55, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 795M/862M [10:31<00:54, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 796M/862M [10:32<00:53, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  92% 797M/862M [10:33<00:52, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 798M/862M [10:34<00:51, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 800M/862M [10:35<00:50, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 801M/862M [10:36<00:49, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 802M/862M [10:37<00:48, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 803M/862M [10:38<00:46, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 805M/862M [10:39<00:45, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  93% 806M/862M [10:40<00:44, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 807M/862M [10:41<00:43, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 808M/862M [10:42<00:42, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 810M/862M [10:43<00:41, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 811M/862M [10:44<00:39, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 812M/862M [10:45<00:39, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  94% 813M/862M [10:46<00:38, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 815M/862M [10:47<00:37, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 816M/862M [10:48<00:36, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 817M/862M [10:49<00:35, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 819M/862M [10:50<00:33, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 820M/862M [10:51<00:32, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 821M/862M [10:52<00:32, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  95% 822M/862M [10:53<00:30, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 824M/862M [10:54<00:29, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 825M/862M [10:55<00:28, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 826M/862M [10:56<00:28, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 828M/862M [10:57<00:27, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 829M/862M [10:58<00:26, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 830M/862M [10:59<00:25, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  96% 831M/862M [11:00<00:24, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 833M/862M [11:01<00:23, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 834M/862M [11:02<00:22, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 835M/862M [11:03<00:21, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 836M/862M [11:04<00:20, 1.33MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 838M/862M [11:05<00:19, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 839M/862M [11:06<00:18, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  97% 840M/862M [11:07<00:17, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 841M/862M [11:08<00:16, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 843M/862M [11:09<00:15, 1.29MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 844M/862M [11:10<00:14, 1.28MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 845M/862M [11:11<00:13, 1.30MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 846M/862M [11:12<00:12, 1.31MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 848M/862M [11:13<00:11, 1.32MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  98% 849M/862M [11:14<00:10, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 850M/862M [11:15<00:09, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 852M/862M [11:16<00:08, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 853M/862M [11:17<00:07, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 854M/862M [11:18<00:06, 1.35MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 855M/862M [11:19<00:05, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin:  99% 857M/862M [11:20<00:04, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 858M/862M [11:21<00:03, 1.36MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 859M/862M [11:22<00:02, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 861M/862M [11:23<00:01, 1.34MB/s]\u001b[A\n",
            "Upload file pytorch_model.bin: 100% 862M/862M [11:24<00:00, 1.34MB/s]\u001b[Aremote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   4c77f7f..a57224b  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   4c77f7f..a57224b  main -> main\n",
            "\n",
            "Upload file runs/Nov21_05-00-17_fb36cbecea73/events.out.tfevents.1669006826.fb36cbecea73.523.0: 100% 22.8k/22.8k [11:26<00:00, 29.1B/s]\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 862M/862M [11:26<00:00, 763kB/s] \u001b[A\n",
            "Upload file pytorch_model.bin: 100% 862M/862M [11:26<00:00, 1.32MB/s]\n",
            "[INFO|modelcard.py:444] 2022-11-21 09:38:28,040 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
            "To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   a57224b..75d1fa8  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   a57224b..75d1fa8  main -> main\n",
            "\n",
            "***** train metrics *****\n",
            "  epoch                    =        5.0\n",
            "  train_loss               =     1.9569\n",
            "  train_runtime            = 4:25:37.65\n",
            "  train_samples            =      24000\n",
            "  train_samples_per_second =      7.529\n",
            "  train_steps_per_second   =      3.765\n",
            "INFO:__main__:*** Evaluate ***\n",
            "[INFO|trainer.py:2907] 2022-11-21 09:38:40,251 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-11-21 09:38:40,251 >>   Num examples = 752\n",
            "[INFO|trainer.py:2912] 2022-11-21 09:38:40,251 >>   Batch size = 2\n",
            "100% 376/376 [21:56<00:00,  3.50s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        5.0\n",
            "  eval_gen_len            =   148.6117\n",
            "  eval_loss               =     1.8165\n",
            "  eval_rouge1             =    64.4504\n",
            "  eval_rouge2             =    35.9206\n",
            "  eval_rougeL             =    38.2078\n",
            "  eval_rougeLsum          =    61.5787\n",
            "  eval_runtime            = 0:22:01.27\n",
            "  eval_samples            =        752\n",
            "  eval_samples_per_second =      0.569\n",
            "  eval_steps_per_second   =      0.285\n",
            "[INFO|trainer.py:2656] 2022-11-21 10:00:41,534 >> Saving model checkpoint to ./vit5-finetune-v6\n",
            "[INFO|configuration_utils.py:447] 2022-11-21 10:00:41,535 >> Configuration saved in ./vit5-finetune-v6/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-11-21 10:00:44,815 >> Model weights saved in ./vit5-finetune-v6/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-11-21 10:00:44,816 >> tokenizer config file saved in ./vit5-finetune-v6/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-11-21 10:00:44,816 >> Special tokens file saved in ./vit5-finetune-v6/special_tokens_map.json\n",
            "[INFO|tokenization_t5_fast.py:187] 2022-11-21 10:00:44,897 >> Copy vocab file to ./vit5-finetune-v6/spiece.model\n",
            "Upload file runs/Nov21_05-00-17_fb36cbecea73/events.out.tfevents.1669024841.fb36cbecea73.523.2: 100% 575/575 [00:00<?, ?B/s]remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   75d1fa8..8f8c6b4  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:remote: Scanning LFS files for validity, may be slow...        \n",
            "remote: LFS file scan complete.        \n",
            "To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   75d1fa8..8f8c6b4  main -> main\n",
            "\n",
            "Upload file runs/Nov21_05-00-17_fb36cbecea73/events.out.tfevents.1669024841.fb36cbecea73.523.2: 100% 575/575 [00:02<?, ?B/s]\n",
            "To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   8f8c6b4..18fe758  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/ynhi/vit5-finetune-v6\n",
            "   8f8c6b4..18fe758  main -> main\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python run_vit5_finetune.py \\\n",
        "    --model_name_or_path VietAI/vit5-base \\\n",
        "    --do_train True \\\n",
        "    --do_eval True \\\n",
        "    --train_file train.csv \\\n",
        "    --validation_file validation.csv \\\n",
        "    --test_file test.csv \\\n",
        "    --text_column inputs \\\n",
        "    --target_column targets \\\n",
        "    --source_prefix \"công thức: \" \\\n",
        "    --output_dir ./vit5-finetune-v6 \\\n",
        "    --per_device_train_batch_size=2 \\\n",
        "    --per_device_eval_batch_size=2 \\\n",
        "    --num_beams 3 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --save_steps 5000 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --predict_with_generate \\\n",
        "    --push_to_hub True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e2afab54a674ee1b16ee5bbd9f99e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2fada7a7c5424569b5004716d5a0808c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386a4e34d8374eea8072e1f99b3b4ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "406d167d234540eabc9a77a631664688": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4f30a855904f2d898063169947eabb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68bbf77271f747829d7ebe5b7ab5bf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8424474433e49428558a62faac3c7be",
              "IPY_MODEL_e63e3e0403dd4dd0a3386ff7fdb1b02c",
              "IPY_MODEL_724619a548e14829b8814cadbcc82000",
              "IPY_MODEL_78d6b30b4df94b74b5e1bd56157d7ef4",
              "IPY_MODEL_ea7a5171242b44b9959b66e1be4ba723"
            ],
            "layout": "IPY_MODEL_2e2afab54a674ee1b16ee5bbd9f99e8f"
          }
        },
        "724619a548e14829b8814cadbcc82000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f2cc978378bf4cada749941cdb5ef7ff",
            "style": "IPY_MODEL_2fada7a7c5424569b5004716d5a0808c",
            "value": true
          }
        },
        "78d6b30b4df94b74b5e1bd56157d7ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_406d167d234540eabc9a77a631664688",
            "style": "IPY_MODEL_386a4e34d8374eea8072e1f99b3b4ddd",
            "tooltip": ""
          }
        },
        "9feb4d678b15442db4614807d2e4686d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6431832942b4e0eb3fa43b56c40ce62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d6b6da352444a4a983746f1426cb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8424474433e49428558a62faac3c7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4f30a855904f2d898063169947eabb",
            "placeholder": "​",
            "style": "IPY_MODEL_9feb4d678b15442db4614807d2e4686d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e63e3e0403dd4dd0a3386ff7fdb1b02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b2d6b6da352444a4a983746f1426cb8a",
            "placeholder": "​",
            "style": "IPY_MODEL_e9346b513b6d4599a63436975f7f2e6b",
            "value": ""
          }
        },
        "e9346b513b6d4599a63436975f7f2e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea7a5171242b44b9959b66e1be4ba723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6431832942b4e0eb3fa43b56c40ce62",
            "placeholder": "​",
            "style": "IPY_MODEL_fc7207fe8f2443c18493c0d219424a97",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f2cc978378bf4cada749941cdb5ef7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc7207fe8f2443c18493c0d219424a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
