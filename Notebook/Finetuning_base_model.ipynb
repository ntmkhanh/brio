{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-UjfsTFQbfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0577bc-4e63-48f2-b813-1758834c8db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/LuanVan/EvaluationBart/transformers-main\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/LuanVan/BRIO\n",
        "%cd /content/drive/MyDrive/LuanVan/EvaluationBart/transformers-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03XK2PKSQf3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ba2b7c-84fd-418b-87ae-7a84a9e42634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting datasets>=1.8.0\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 66.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from -r examples/pytorch/summarization/requirements.txt (line 4)) (3.19.6)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from -r examples/pytorch/summarization/requirements.txt (line 6)) (3.7)\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.8/dist-packages (from -r examples/pytorch/summarization/requirements.txt (line 8)) (1.13.0+cu116)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (4.64.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 74.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2022.11.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (0.3.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 80.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3->-r examples/pytorch/summarization/requirements.txt (line 8)) (4.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate->-r examples/pytorch/summarization/requirements.txt (line 1)) (5.4.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge-score->-r examples/pytorch/summarization/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge-score->-r examples/pytorch/summarization/requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->-r examples/pytorch/summarization/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->-r examples/pytorch/summarization/requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->-r examples/pytorch/summarization/requirements.txt (line 6)) (2022.6.2)\n",
            "Collecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[K     |████████████████████████████████| 378 kB 81.8 MB/s \n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 49.2 MB/s \n",
            "\u001b[?25hCollecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets>=1.8.0->-r examples/pytorch/summarization/requirements.txt (line 2)) (2.8.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=c00421f6bc93d3c4bdc1da02741e526c2921fff19a4f66f60cc00f4a70a2f6d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, texttable, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, datasets, brotli, sentencepiece, rouge-score, py7zr, evaluate, accelerate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed accelerate-0.15.0 brotli-1.0.9 datasets-2.7.1 evaluate-0.3.0 huggingface-hub-0.11.1 inflate64-0.3.1 multiprocess-0.70.14 multivolumefile-0.2.3 py7zr-0.20.2 pybcj-1.0.1 pycryptodomex-3.16.0 pyppmd-1.0.0 pyzstd-0.15.3 responses-0.18.0 rouge-score-0.1.2 sentencepiece-0.1.97 texttable-1.6.7 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -r examples/pytorch/summarization/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8au5gRl1R5Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340ac6ae-2e97-455b-d82f-2742f218e702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-pa_etd0i\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-pa_etd0i\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.26.0.dev0) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.26.0.dev0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.26.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.26.0.dev0) (1.25.11)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.26.0.dev0-py3-none-any.whl size=5949145 sha256=dd7896ca0b784071532baee0692f8b2d4473bdebbdd57bea8d2bdb4e24725a92\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z8zv25g_/wheels/42/68/45/c63edff61c292f2dfd4df4ef6522dcbecc603e7af82813c1d7\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.2 transformers-4.26.0.dev0\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install transformers==4.6.0"
      ],
      "metadata": {
        "id": "xrzv7kC_IK1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\n",
        "#         \"vinai/bartpho-word-base\",\n",
        "#         use_fast=True,\n",
        "#         revision=\"main\",\n",
        "#         use_auth_token= None,\n",
        "#     )\n",
        "# print(tokenizer.decode([0, 6010, 18241, 8, 58, 2122, 11, 47, 39, 3797, 151, 17167, 1722, 1074, 6, 933, 23358, 5, 2085, 6010, 18241, 11, 15952, 143, 36, 166, 2004, 85, 42, 8416, 3031, 4, 28486, 5, 166, 58, 2122, 23, 475, 2122, 44630, 7, 6222, 4, 10, 1465, 29347, 4, 626, 2733, 4, 4205, 11812, 6, 2023, 5, 58, 2122, 6010, 18241, 10, 12, 1399, 1953, 25, 55361, 5, 284, 27, 18542, 42855, 2689, 6821, 14487, 5, 139, 47, 6010, 18241, 281, 972, 5, 88, 66, 115, 59763, 1517, 2734, 9, 166, 2004, 42, 44630, 4, 933, 38875, 4, 1347, 35699, 9293, 4, 3797, 7122, 63, 899, 549, 33, 12, 58, 6, 143, 2304, 3692, 42, 1886, 4, 2140, 24, 2122, 893, 7578, 5, 1397, 24, 47, 40, 11, 166, 2122, 156, 287, 4088, 6, 6960, 55361, 54, 17, 592, 5, 2]))"
      ],
      "metadata": {
        "id": "lNJbBa-_-Uqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ViT5 FOR VIETNAMESE"
      ],
      "metadata": {
        "id": "wwjCuF7P37qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python examples/pytorch/summarization/run_summarization_viet_vit5.py \\\n",
        "#     --model_name_or_path /content/drive/MyDrive/LuanVan/BRIO/finetuned_model/vit5/checkpoint-41187 \\\n",
        "#     --do_train \\\n",
        "#     --do_predict \\\n",
        "#     --tokenizer_name /content/drive/MyDrive/LuanVan/BRIO/finetuned_model/vit5/checkpoint-41187 \\\n",
        "#     --num_train_epochs 5 \\\n",
        "#     --learning_rate 1e-5 \\\n",
        "#     --warmup_ratio=0.05 \\\n",
        "#     --weight_decay=0.01\\\n",
        "#     --train_file /content/drive/MyDrive/LuanVan/BRIO/ctufinetune/train.csv \\\n",
        "#     --validation_file /content/drive/MyDrive/LuanVan/BRIO/ctufinetune/val.csv \\\n",
        "#     --test_file /content/drive/MyDrive/LuanVan/BRIO/ctufinetune/test.csv \\\n",
        "#     --output_dir /content/drive/MyDrive/LuanVan/BRIO/finetuned_model/vit5_2 \\\n",
        "#     --overwrite_output_dir \\\n",
        "#     --per_device_train_batch_size=4 \\\n",
        "#     --per_device_eval_batch_size=4 \\\n",
        "#     --predict_with_generate \\\n",
        "#     --evaluation_strategy=\"epoch\" \\\n",
        "#     --save_strategy=\"epoch\" \\\n",
        "#     --text_column text \\\n",
        "#     --summary_column summary \\\n",
        "#     --save_total_limit=3 \\\n",
        "#     --load_best_model_at_end=True \\\n",
        "#     --max_source_length=512 \\\n",
        "#     --fp16=True"
      ],
      "metadata": {
        "id": "5gt7nj5p36uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MBART FOR VIETNAMESE"
      ],
      "metadata": {
        "id": "mxCkOg_Lt3Gx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZrFk8o2QjoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9e1526-9d41-4643-b898-56c80f7e38a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final/runs/Dec10_12-09-05_b5e1cf9375ea,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=/content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=no,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=20000,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final/runs/Dec10_12-09-05_b5e1cf9375ea,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=/content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=no,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=20000,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "WARNING:datasets.builder:Using custom data configuration default-3203e3a825cd09d7\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.8/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.builder:Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-3203e3a825cd09d7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-3203e3a825cd09d7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
            "Downloading data files: 100% 3/3 [00:00<00:00, 3808.39it/s]\n",
            "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
            "INFO:datasets.utils.py_utils:Spawning 3 processes for 3 objects in slices of [1, 1, 1]\n",
            "\n",
            "Extracting data files #0:   0% 0/1 [00:00<?, ?obj/s]\n",
            "\n",
            "Extracting data files #1: 100% 1/1 [00:00<00:00, 48.15obj/s]\n",
            "Extracting data files #2: 100% 1/1 [00:00<00:00, 41.75obj/s]\n",
            "Extracting data files #0: 100% 1/1 [00:00<00:00, 27.50obj/s]\n",
            "INFO:datasets.utils.py_utils:Finished 3 processes\n",
            "INFO:datasets.utils.py_utils:Unpacked 3 objects\n",
            "INFO:datasets.utils.info_utils:Unable to verify checksums.\n",
            "INFO:datasets.builder:Generating train split\n",
            "INFO:datasets.builder:Generating validation split\n",
            "INFO:datasets.builder:Generating test split\n",
            "INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-3203e3a825cd09d7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 653.11it/s]\n",
            "Downloading: 100% 898/898 [00:00<00:00, 1.14MB/s]\n",
            "[INFO|configuration_utils.py:654] 2022-12-10 12:09:15,882 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--bartpho-word-base/snapshots/558969fe5aeaabfbd2eb5a59ab4908803cd9788d/config.json\n",
            "[INFO|configuration_utils.py:706] 2022-12-10 12:09:15,883 >> Model config MBartConfig {\n",
            "  \"_name_or_path\": \"vinai/bartpho-word-base\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"MBartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"mbart\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tokenizer_class\": \"PhobertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:450] 2022-12-10 12:09:16,024 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:654] 2022-12-10 12:09:16,170 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--bartpho-word-base/snapshots/558969fe5aeaabfbd2eb5a59ab4908803cd9788d/config.json\n",
            "[INFO|configuration_utils.py:706] 2022-12-10 12:09:16,171 >> Model config MBartConfig {\n",
            "  \"_name_or_path\": \"vinai/bartpho-word-base\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"MBartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"mbart\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tokenizer_class\": \"PhobertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "Downloading: 100% 895k/895k [00:00<00:00, 5.07MB/s]\n",
            "Downloading: 100% 1.14M/1.14M [00:00<00:00, 6.56MB/s]\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-12-10 12:09:17,418 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--vinai--bartpho-word-base/snapshots/558969fe5aeaabfbd2eb5a59ab4908803cd9788d/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-12-10 12:09:17,418 >> loading file bpe.codes from cache at /root/.cache/huggingface/hub/models--vinai--bartpho-word-base/snapshots/558969fe5aeaabfbd2eb5a59ab4908803cd9788d/bpe.codes\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-12-10 12:09:17,418 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-12-10 12:09:17,418 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-12-10 12:09:17,418 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:654] 2022-12-10 12:09:17,418 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--vinai--bartpho-word-base/snapshots/558969fe5aeaabfbd2eb5a59ab4908803cd9788d/config.json\n",
            "[INFO|configuration_utils.py:706] 2022-12-10 12:09:17,419 >> Model config MBartConfig {\n",
            "  \"_name_or_path\": \"vinai/bartpho-word-base\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"MBartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"mbart\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tokenizer_class\": \"PhobertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64001\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils.py:426] 2022-12-10 12:09:17,532 >> Adding <mask> to the vocabulary\n",
            "[WARNING|logging.py:281] 2022-12-10 12:09:17,532 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading: 100% 600M/600M [00:06<00:00, 91.2MB/s]\n",
            "[INFO|modeling_utils.py:2238] 2022-12-10 12:09:24,470 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--vinai--bartpho-word-base/snapshots/558969fe5aeaabfbd2eb5a59ab4908803cd9788d/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2742] 2022-12-10 12:09:26,603 >> All model checkpoint weights were used when initializing MBartForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:2750] 2022-12-10 12:09:26,603 >> All the weights of MBartForConditionalGeneration were initialized from the model checkpoint at vinai/bartpho-word-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MBartForConditionalGeneration for predictions without further training.\n",
            "Running tokenizer on prediction dataset:   0% 0/13 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-3203e3a825cd09d7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-7369c267fdc58af6.arrow\n",
            "Running tokenizer on prediction dataset: 100% 13/13 [00:25<00:00,  2.00s/ba]\n",
            "Downloading builder script: 100% 6.27k/6.27k [00:00<00:00, 7.93MB/s]\n",
            "INFO:__main__:*** Predict ***\n",
            "[INFO|trainer.py:710] 2022-12-10 12:09:59,294 >> The following columns in the test set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2956] 2022-12-10 12:09:59,297 >> ***** Running Prediction *****\n",
            "[INFO|trainer.py:2958] 2022-12-10 12:09:59,297 >>   Num examples = 12581\n",
            "[INFO|trainer.py:2961] 2022-12-10 12:09:59,297 >>   Batch size = 4\n",
            "100% 3146/3146 [1:32:54<00:00,  1.77s/it]\n",
            "***** predict metrics *****\n",
            "  predict_gen_len            =    132.837\n",
            "  predict_loss               =     3.6785\n",
            "  predict_rouge1             =    42.7731\n",
            "  predict_rouge2             =     22.248\n",
            "  predict_rougeL             =    27.6901\n",
            "  predict_rougeLsum          =    33.6794\n",
            "  predict_runtime            = 1:32:59.78\n",
            "  predict_samples            =      12581\n",
            "  predict_samples_per_second =      2.255\n",
            "  predict_steps_per_second   =      0.564\n",
            "[INFO|modelcard.py:449] 2022-12-10 13:43:30,262 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Summarization', 'type': 'summarization'}}\n"
          ]
        }
      ],
      "source": [
        "!python examples/pytorch/summarization/run_summarization_viet.py \\\n",
        "    --model_name_or_path \"vinai/bartpho-word-base\" \\\n",
        "    --do_train\n",
        "    --do_predict \\\n",
        "    --tokenizer_name \"vinai/bartpho-word-base\" \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --learning_rate 0.00001 \\\n",
        "    --warmup_steps 20000 \\\n",
        "    --train_file /content/drive/MyDrive/LuanVan/BRIO/ctufinetune/train.csv \\\n",
        "    --validation_file /content/drive/MyDrive/LuanVan/BRIO/ctufinetune/val.csv \\\n",
        "    --test_file /content/drive/MyDrive/LuanVan/BRIO/ctufinetune/test.csv \\\n",
        "    --output_dir /content/drive/MyDrive/LuanVan/BRIO/finetuned_model/eval_bartpho_final \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size=4 \\\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --predict_with_generate \\\n",
        "    --evaluation_strategy=\"no\" \\\n",
        "    --save_strategy=\"no\" \\\n",
        "    --text_column text \\\n",
        "    --summary_column summary \\\n",
        "    --save_total_limit=1 \\\n",
        "    --load_best_model_at_end=True \\\n",
        "    --max_source_length=1024 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " BART FOR ENGLISH"
      ],
      "metadata": {
        "id": "bC6ngAQ0uGLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python examples/pytorch/summarization/run_summarization.py \\\n",
        "#     --model_name_or_path \"facebook/bart-large-cnn\" \\\n",
        "#     --do_train \\\n",
        "#     --do_eval \\\n",
        "#     --do_predict \\\n",
        "#     --num_train_epochs 1 \\\n",
        "#     --train_file /content/drive/MyDrive/LuanVan/BRIO/cnndm_new/cnndm_csv/train.csv \\\n",
        "#     --validation_file /content/drive/MyDrive/LuanVan/BRIO/cnndm_new/cnndm_csv/val.csv \\\n",
        "#     --test_file /content/drive/MyDrive/LuanVan/BRIO/cnndm_new/cnndm_csv/test.csv \\\n",
        "#     --output_dir /content/drive/MyDrive/LuanVan/BRIO/finetuned_model/bartbase \\\n",
        "#     --overwrite_output_dir \\\n",
        "#     --per_device_train_batch_size=4 \\\n",
        "#     --per_device_eval_batch_size=4 \\\n",
        "#     --predict_with_generate \\\n",
        "#     --evaluation_strategy=\"no\" \\\n",
        "#     --save_strategy=\"no\" \\\n",
        "#     --text_column text \\\n",
        "#     --summary_column summary \\\n",
        "#     --save_total_limit=1 \\\n",
        "#     --load_best_model_at_end=True \\\n",
        "#     --max_source_length=1024 "
      ],
      "metadata": {
        "id": "0aR5R3l3uEex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "T5 FOR ENGLISH"
      ],
      "metadata": {
        "id": "jlXMz_Av5rcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# python examples/pytorch/summarization/run_summarization.py \\\n",
        "#     --model_name_or_path t5-base \\\n",
        "#     --do_train \\\n",
        "#     --do_eval \\\n",
        "#     --do_train \\\n",
        "#     --num_train_epochs 1 \\\n",
        "#     --train_file /content/drive/MyDrive/LuanVan/BRIO/cnndm_new/cnndm_csv/train.csv \\\n",
        "#     --validation_file /content/drive/MyDrive/LuanVan/BRIO/cnndm_new/cnndm_csv/val.csv \\\n",
        "#     --test_file /content/drive/MyDrive/LuanVan/BRIO/cnndm_new/cnndm_csv/test.csv \\\n",
        "#     --output_dir /content/drive/MyDrive/LuanVan/BRIO/finetuned_model/t5_base \\\n",
        "#     --source_prefix \"summarize: \" \\\n",
        "#     --output_dir /tmp/tst-summarization \\\n",
        "#     --per_device_train_batch_size=4 \\\n",
        "#     --per_device_eval_batch_size=4 \\\n",
        "#     --overwrite_output_dir \\\n",
        "#     --predict_with_generate"
      ],
      "metadata": {
        "id": "Rq0opVz45q1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}